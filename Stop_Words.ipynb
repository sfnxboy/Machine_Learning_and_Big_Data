{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stop_Words.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZW2l8aGFV04",
        "outputId": "a6a95d4e-c7df-48a9-8436-3207e861e66d"
      },
      "source": [
        "import os\r\n",
        "# Find the latest version of spark 3.0  from http://www-us.apache.org/dist/spark/ and enter as the spark version\r\n",
        "# For example:\r\n",
        "# spark_version = 'spark-3.0.1'\r\n",
        "spark_version = 'spark-3.0.1'\r\n",
        "os.environ['SPARK_VERSION']=spark_version\r\n",
        "\r\n",
        "# Install Spark and Java\r\n",
        "!apt-get update\r\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\r\n",
        "!wget -q http://www-us.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\r\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\r\n",
        "!pip install -q findspark\r\n",
        "\r\n",
        "# Set Environment Variables\r\n",
        "import os\r\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\r\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\r\n",
        "\r\n",
        "# Start a SparkSession\r\n",
        "import findspark\r\n",
        "findspark.init()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rIgn:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (91.18\r                                                                               \rIgn:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (91.18\r                                                                               \rHit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (91.18\r0% [Release.gpg gpgv 697 B] [Connecting to archive.ubuntu.com (91.189.88.152)] \r                                                                               \rHit:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:5 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:6 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:10 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Reading package lists... Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbdvf_pwFatV"
      },
      "source": [
        " # Start Spark session\r\n",
        "from pyspark.sql import SparkSession\r\n",
        "spark = SparkSession.builder.appName(\"StopWords\").getOrCreate()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njxjP8tBFc6u",
        "outputId": "55cef9d4-2489-4dc8-a2fd-08ddd31110d5"
      },
      "source": [
        "# Create sample Dataframe\r\n",
        "sentenceData = spark.createDataFrame([\r\n",
        "                                   (0, \"My name is Amir ElTabakh\"),\r\n",
        "                                   (1, \"I am a junior in college at this time\"),\r\n",
        "                                   (2, \"I am interning at NASA\")\r\n",
        "], [\"id\", \"raw\"])\r\n",
        "\r\n",
        "sentenceData.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+--------------------+\n",
            "| id|                 raw|\n",
            "+---+--------------------+\n",
            "|  0|My name is Amir E...|\n",
            "|  1|I am a junior in ...|\n",
            "|  2|I am interning at...|\n",
            "+---+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ie7Z85E-HyMn",
        "outputId": "d3466054-6416-485e-ebfa-dbc25ce92ee7"
      },
      "source": [
        "# Import the Tokenizer library\r\n",
        "from pyspark.ml.feature import Tokenizer\r\n",
        "\r\n",
        "# Initialize tokenizer variable\r\n",
        "tokenizer = Tokenizer(inputCol=\"raw\", outputCol=\"words\")\r\n",
        "\r\n",
        "# Transform and show DataFrame\r\n",
        "tokenized_df = tokenizer.transform(sentenceData)\r\n",
        "tokenized_df.show(truncate=False)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+-------------------------------------+-----------------------------------------------+\n",
            "|id |raw                                  |words                                          |\n",
            "+---+-------------------------------------+-----------------------------------------------+\n",
            "|0  |My name is Amir ElTabakh             |[my, name, is, amir, eltabakh]                 |\n",
            "|1  |I am a junior in college at this time|[i, am, a, junior, in, college, at, this, time]|\n",
            "|2  |I am interning at NASA               |[i, am, interning, at, nasa]                   |\n",
            "+---+-------------------------------------+-----------------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJlaA83lFn8J"
      },
      "source": [
        "# Import the StopWordsRemove library\r\n",
        "from pyspark.ml.feature import StopWordsRemover"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yQ1mHT1FtkP"
      },
      "source": [
        "# Run the Remover\r\n",
        "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_cBP1s-GcoV"
      },
      "source": [
        "The StopWordsRemover() function, which takes an input column that will be passed into the function, and an output column to add the results. This is stored in a variable for ease of use. The outcome shows the raw data, or input, and the result of running the StopWordsRemover() function. In the filtered column, all the stop words are removed and the result is displayed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VG0lewuKFwvJ",
        "outputId": "01979d04-6dfb-4216-fc76-cb1a2a8f0b7c"
      },
      "source": [
        "# Transform and show data\r\n",
        "remover.transform(tokenized_df).show(truncate=False)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+-------------------------------------+-----------------------------------------------+-----------------------+\n",
            "|id |raw                                  |words                                          |filtered               |\n",
            "+---+-------------------------------------+-----------------------------------------------+-----------------------+\n",
            "|0  |My name is Amir ElTabakh             |[my, name, is, amir, eltabakh]                 |[name, amir, eltabakh] |\n",
            "|1  |I am a junior in college at this time|[i, am, a, junior, in, college, at, this, time]|[junior, college, time]|\n",
            "|2  |I am interning at NASA               |[i, am, interning, at, nasa]                   |[interning, nasa]      |\n",
            "+---+-------------------------------------+-----------------------------------------------+-----------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}